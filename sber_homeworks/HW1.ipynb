{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mun7SyNQV7TA",
        "VNzMg4gxV7TA"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:18:43.325903Z",
          "start_time": "2021-04-17T09:18:43.321914Z"
        },
        "id": "SOtW61Z_V7Se"
      },
      "source": [
        "# Тренировка нейронных сетей на реальных данных\n",
        "\n",
        "## Классификация котов и собак"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E65Y8aDV7Sn"
      },
      "source": [
        "# Запускать только если вы работаете в google collab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:00.652880Z",
          "start_time": "2021-04-17T09:31:00.646898Z"
        },
        "id": "osMdnRWkV7So"
      },
      "source": [
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBBvKt2vV7Sp"
      },
      "source": [
        "Определим в одном месте все константы, которые понадобятся нам в дальнейшем. Их смысл будет прояснён по мере использования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:01.256152Z",
          "start_time": "2021-04-17T09:31:01.251140Z"
        },
        "id": "FwlhcyxNV7Sp"
      },
      "source": [
        "### Let's have a cell with global hyperparameters for the CNNs in this notebook\n",
        "\n",
        "# Path to a directory with image dataset and subfolders for training, validation and final testing\n",
        "DATA_PATH = 'data' # PATH TO THE DATASET\n",
        "\n",
        "# Number of threads for data loader\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Image size: even though image sizes are bigger than 96, we use this to speed up training\n",
        "SIZE_H = SIZE_W = 96\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# Number of classes in the dataset\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Epochs: number of passes over the training data, we use it this small to reduce training babysitting time\n",
        "EPOCH_NUM = 30\n",
        "\n",
        "# Batch size: for batch gradient descent optimization, usually selected as 2**K elements\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Images mean and std channelwise\n",
        "image_mean = [0.485, 0.456, 0.406]\n",
        "image_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Last layer (embeddings) size for CNN models\n",
        "EMBEDDING_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:02.357576Z",
          "start_time": "2021-04-17T09:31:02.261833Z"
        },
        "id": "SToZnTvaV7Sq"
      },
      "source": [
        "# используем GPU при наличии\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:03.502176Z",
          "start_time": "2021-04-17T09:31:03.452308Z"
        },
        "id": "X_ZdW4DkV7Sq"
      },
      "source": [
        "!wget -nc https://www.dropbox.com/s/gqdo90vhli893e0/data.zip\n",
        "!unzip -n data.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:09.352658Z",
          "start_time": "2021-04-17T09:31:09.348670Z"
        },
        "id": "2phj2vOnV7Sr"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((SIZE_H, SIZE_W)),        # scaling images to fixed size\n",
        "    transforms.ToTensor(),                      # converting to tensors\n",
        "    transforms.Normalize(image_mean, image_std) # normalize image data per-channel\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:09.818701Z",
          "start_time": "2021-04-17T09:31:09.799750Z"
        },
        "id": "4oLkBZKcV7Sr"
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'train_11k'), transform=transformer)\n",
        "val_dataset   = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'val'), transform=transformer)\n",
        "test_dataset  = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'test_labeled'), transform=transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:10.245710Z",
          "start_time": "2021-04-17T09:31:10.232737Z"
        },
        "id": "QKpOvEZgV7Ss"
      },
      "source": [
        "n_train, n_val, n_test = len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGGKnqzIV7Ss"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLXaDjBV7St"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51tm4l4pV7St"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:22.137667Z",
          "start_time": "2021-04-17T09:31:22.133648Z"
        },
        "id": "QG3EkVwBV7St"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:32:06.060430Z",
          "start_time": "2021-04-17T09:32:06.051427Z"
        },
        "id": "xEBZGPXlV7Su"
      },
      "source": [
        "def train_model(model, train_loader, val_loader, loss_fn, opt, n_epochs):\n",
        "    '''\n",
        "    model: нейросеть для обучения,\n",
        "    train_loader, val_loader: загрузчики данных\n",
        "    loss_fn: целевая метрика (которую будем оптимизировать)\n",
        "    opt: оптимизатор (обновляет веса нейросети)\n",
        "    n_epochs: кол-во эпох, полных проходов датасета\n",
        "    '''\n",
        "    train_loss = []\n",
        "    val_accuracy = []\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train(True) # enable dropout / batch_norm training behavior\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # move data to target device\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            # train on batch: compute loss, calc grads, perform optimizer step and zero the grads\n",
        "            opt.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = loss_fn(predictions, y_batch)\n",
        "            loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "            opt.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        model.train(False) # disable dropout / use averages for batch_norm\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # move data to target device\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            # compute logits\n",
        "            logits = model(X_batch)\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "        # print the results for this epoch:\n",
        "        print(f'Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s')\n",
        "\n",
        "        train_loss_value = np.mean(train_loss[-n_train // BATCH_SIZE :])\n",
        "        val_accuracy_value = np.mean(val_accuracy[-n_val // BATCH_SIZE :]) * 100\n",
        "        \n",
        "        print(f\"  training loss (in-iteration): \\t{train_loss_value:.6f}\")\n",
        "        print(f\"  validation accuracy: \\t\\t\\t{val_accuracy_value:.2f} %\")\n",
        "\n",
        "    return train_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQT91OLV7Su"
      },
      "source": [
        "## Задание 1. Реализовать сверточную нейросеть для классификации котов и собак (0.4 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdTmtSFnV7Sv"
      },
      "source": [
        "### First step\n",
        "\n",
        "**conv-pool-conv-pool-dense-dense!**\n",
        "\n",
        "Создайте мини-сверточную нейронную сеть со следующей структурой:\n",
        "* Входной слой\n",
        "* 3 классических сверточных блока`convolution->relu->pool`: \n",
        "  * свертка 3x3 с 128 фильтрами и функцией активации _ReLU_\n",
        "  * 2x2 пулинг (или поставьте для предыдущей свертки страйд = 3)\n",
        " * Flatten\n",
        "* 30% Dropout \n",
        "* Линейный слой с 256 нейронами и функцией активации _ReLU_\n",
        "* 30% dropout\n",
        "* Выходной линейный слой.\n",
        "\n",
        "__Convolutional layers__ в торче создаются как любой другой слой, но у него есть особые параметры:\n",
        "\n",
        "__`...`__\n",
        "\n",
        "__`model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)) # светрка`__\n",
        "\n",
        "__`model.add_module('pool1', nn.MaxPool2d(2)) # max pooling 2 на 2`__\n",
        "\n",
        "__`...`__\n",
        "\n",
        "\n",
        "Когда вы закончите создание нейросети (когда функция compute_loss не будет поднимать ошибки), обучите её с оптимайзером __Adam__ с LR = 3e-4 (Константа Карпатого)\n",
        "\n",
        "Если всё верно, вы должны получить минимум __75%__ точности на валидации.\n",
        "\n",
        "__ХАК_ДНЯ__ : количество каналов должно быть в порядке количества class_labels\n",
        "\n",
        "__ХАК_ДНЯ_2__ : вы можете поставить stride=2 для Conv2d слоя чтобы увеличить скорость обучения, но помните про размерности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:28.434449Z",
          "start_time": "2021-04-17T09:31:24.047455Z"
        },
        "id": "CB02Gi8_V7Sw"
      },
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "# Your code here: CONV->POOL->CONV-POOL->... as many as you wish\n",
        "\n",
        "# End of your code here\n",
        "# global average pooling\n",
        "model_cnn.add_module('gap_5', nn.AvgPool2d(20))\n",
        "# dropout for regularization\n",
        "model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "# \"flatten\" the data\n",
        "model_cnn.add_module('flat', Flatten())\n",
        "# last fully-connected layer, used to create embedding vectors\n",
        "model_cnn.add_module('fc_6', nn.Linear(128, EMBEDDING_SIZE))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "\n",
        "model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "# logits for NUM_CLASSES=2 classes\n",
        "model_cnn.add_module('fc_logits', nn.Linear(EMBEDDING_SIZE, NUM_CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "# move model to computing device\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxZ1lYqpV7Sw"
      },
      "source": [
        "\n",
        "__Подсказка:__ Можно не считать размерности слоев руками, просто вставьте любую размерность и запуститите (например, 1 юнит) и  запустите compute_loss. Вы увидите что-то в духе:\n",
        "\n",
        "__`RuntimeError: size mismatch, m1: [5 x 1960], m2: [1 x 64] at /some/long/path/to/torch/operation`__\n",
        "\n",
        "Видите __1960__? Это та размерность, которую вам нужно выставить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdqMYf-fWbZi"
      },
      "source": [
        "summary(model_cnn, train_dataset[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:33:15.099833Z",
          "start_time": "2021-04-17T09:33:15.095846Z"
        },
        "id": "QXb0NQzxV7Sw"
      },
      "source": [
        "#Оптимайзер\n",
        "opt = ??\n",
        "\n",
        "#Функция потерь (Лосс функция)\n",
        "loss_fn = ??\n",
        "\n",
        "#Число эпох\n",
        "n_epochs = ??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:32:09.317666Z",
          "start_time": "2021-04-17T09:32:09.305678Z"
        },
        "id": "s67hp0JeV7Sx"
      },
      "source": [
        "opt.zero_grad()\n",
        "model_cnn, opt, losses_cnn = train_model(model_cnn,\n",
        "                                         train_loader,\n",
        "                                         val_loader,\n",
        "                                         loss_fn,\n",
        "                                         opt,\n",
        "                                         n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NolBHw_jV7Sx"
      },
      "source": [
        "def test_model(model, test_loader, subset='test'):\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    test_batch_acc = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        logits = model(X_batch.to(device))\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    test_accuracy = np.mean(test_batch_acc)\n",
        "    \n",
        "    print(\"Results:\")\n",
        "    print(f\"  {subset} accuracy:\\t\\t{test_accuracy * 100:.2f} %\")\n",
        "    if test_accuracy > 0.9:\n",
        "        print(\"Amazing!\")\n",
        "    elif test_accuracy > 0.7:\n",
        "        print(\"Good!\")\n",
        "    else:\n",
        "        print(\"We need more magic! Follow instructons below\")\n",
        "    return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vn_sEQV7Sx"
      },
      "source": [
        "best_model_cnn = None\n",
        "\n",
        "val_accuracy = test_model(best_model_cnn, val_loader, subset='val')\n",
        "test_accuracy = test_model(best_model_cnn, test_loader, subset='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccLKfj1cV7Sy"
      },
      "source": [
        "__Конец первой части__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iacZz7qV7Sy"
      },
      "source": [
        "# CVAE  (0.3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJcdOwj_V7Sy"
      },
      "source": [
        "Теперь построим CVAE модель. Её отличие в том, что на вход энкодеру и декодеру подаётся значение цифры. Таким образом, модели уже не нужно запоминать значение цифры в латентном коде, т.к. одно добавляется нами вручную.\n",
        "\n",
        "**Упражнение:** Реализуйте CVAE, модифицировав VAE с использованием полносвязных слоёв, который был разобран в начале семинара. \n",
        "\n",
        "Значения лэйблов (y) в виде one-hot векторов нужно присоединить (конкатенировать) к векторам, которые подаются на вход энкодеру и декодеру.\n",
        "\n",
        "Для получение one-hot векторов используйте функцию F.one_hot(input, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:11.149056Z",
          "start_time": "2021-04-17T09:52:11.136060Z"
        },
        "id": "8gYRi9_6V7Sy"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from ipywidgets import interact\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from functools import reduce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:18.629825Z",
          "start_time": "2021-04-17T09:52:18.624836Z"
        },
        "id": "0UB-ki4sV7Sz"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:52.629342Z",
          "start_time": "2021-04-17T09:52:52.605407Z"
        },
        "id": "gEyqeaZiV7Sz"
      },
      "source": [
        "# MNIST dataset\n",
        "dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                     train=True,\n",
        "                                     transform=transforms.ToTensor(),\n",
        "                                     download=True)\n",
        "\n",
        "# Data loader\n",
        "batch_size = 32\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:52.917573Z",
          "start_time": "2021-04-17T09:52:52.905604Z"
        },
        "id": "Qk0P8oy7V7S0"
      },
      "source": [
        "@interact(i=(0, len(dataset)-1))\n",
        "def f(i):\n",
        "    print(dataset[i][1])\n",
        "    plt.imshow(dataset[i][0].numpy()[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBHUdWnmnGcg"
      },
      "source": [
        "#Создаем модель\n",
        "#Your code goes here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-psxxNbrV7S0"
      },
      "source": [
        "# CVAE model\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, image_size=im_size*im_size, z_size=20):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(\"YOUR CODE GOES HERE\", 400)\n",
        "\n",
        "        self.fc2 = nn.Linear(400, 128)\n",
        "        self.fc3 = nn.Linear(128, z_size)\n",
        "        self.fc4 = nn.Linear(128, z_size)\n",
        "        self.fc5 = nn.Linear(\"YOUR CODE GOES HERE\", 400)\n",
        "\n",
        "        self.fc6 = nn.Linear(400, image_size)\n",
        "        \n",
        "    def encode(self, x, y):\n",
        "        x = # YOUR CODE GOES HERE\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x), self.fc4(x)\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        z = # YOUR CODE GOES HERE\n",
        "        x = F.relu(self.fc5(z))\n",
        "        return F.sigmoid(self.fc6(x))\n",
        "    \n",
        "    def forward(self, x, y1, y2):\n",
        "        mu, log_var = # YOUR CODE GOES HERE\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_reconst = # YOUR CODE GOES HERE\n",
        "        return x_reconst, mu, log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh0mNt3VV7S1"
      },
      "source": [
        "def train(model, data_reader, optimizer, inp_shape, num_epochs=num_epochs):\n",
        "    # Start training\n",
        "    loss1 = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x, y) in enumerate(data_loader):\n",
        "            # Forward pass\n",
        "            x = x.to(device).view(inp_shape)\n",
        "            y = # YOUR CODE GOES HERE\n",
        "            x_reconst, mu, log_var = # YOUR CODE GOES HERE\n",
        "\n",
        "            # Compute reconstruction loss and kl divergence\n",
        "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
        "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "            # Backprop and optimize\n",
        "            loss = reconst_loss + kl_div\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                loss1.append(loss.item())\n",
        "                pl.plot(loss1, color='red')\n",
        "                display.clear_output(wait=True)\n",
        "                display.display(pl.gcf())\n",
        "                print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
        "                      .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4VaixgCV7S1"
      },
      "source": [
        "model = CVAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train(model, data_loader, optimizer, (-1, im_size * im_size), num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quHtp6N7V7S2"
      },
      "source": [
        "n = 10\n",
        "from scipy.stats import norm\n",
        "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры, берем из обратной функции распределения\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "def draw_manifold(model, lbl, show=True):\n",
        "    with torch.no_grad():\n",
        "        # Рисование цифр из многообразия\n",
        "        figure = np.zeros((im_size * n, im_size * n))\n",
        "        input_lbl = np.zeros((1, 10))\n",
        "        input_lbl[0, lbl] = 1\n",
        "        for i, yi in enumerate(grid_y):\n",
        "            for j, xi in enumerate(grid_x):\n",
        "                z_sample = np.zeros((1, 20))\n",
        "                z_sample[:, :2] = np.array([[xi, yi]])\n",
        "                z_sample = torch.tensor(z_sample, dtype=torch.float).to(device)\n",
        "                input_lbl = torch.tensor(input_lbl, dtype=torch.float).to(device)\n",
        "                x_decoded = model.decode(z_sample, torch.tensor(lbl).reshape(-1)).cpu().numpy().reshape((im_size, im_size))\n",
        "                digit = x_decoded.squeeze() \n",
        "                figure[i * im_size: (i + 1) * im_size,\n",
        "                    j * im_size: (j + 1) * im_size] = digit\n",
        "        if show:\n",
        "            # Визуализация\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(figure, cmap='gray')\n",
        "            plt.grid(False)\n",
        "            ax = plt.gca()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "            plt.show()\n",
        "    return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV5L0xw5V7S2"
      },
      "source": [
        "for i in range(10):\n",
        "    draw_manifold(model, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSKNDpZfV7S2"
      },
      "source": [
        "# GAN 0.3 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:57:45.770866Z",
          "start_time": "2021-04-17T09:57:45.687089Z"
        },
        "id": "jkK08CQUV7S3"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuKl0tnGV7S3"
      },
      "source": [
        "!wget https://www.dropbox.com/s/329oy3cprlvn5vb/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY4uINpPV7S3"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('archive.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phCOXQj_V7S3"
      },
      "source": [
        "DATA_DIR = './cats/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ask2vXx9V7S4"
      },
      "source": [
        "# set parameters of the transformed data\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5RZA81V7S4"
      },
      "source": [
        "# As dataset is stored in the directory, we can create dataset\n",
        "# as ImageFolder PyTorch object and set all the transformations here\n",
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose([\n",
        "    tt.ToTensor(),\n",
        "    tt.Normalize(*stats)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcX3TiTtV7S4"
      },
      "source": [
        "# Create PyTorch DataLoader object to produce batches\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP8z4DF4V7S4"
      },
      "source": [
        "# for the nicer images visualization \n",
        "# we make inverse transformation for normalization\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii8EDftgV7S5"
      },
      "source": [
        "# functions to plot images\n",
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "def show_batch(dl, nmax=64):\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAS1Zk7tV7S5"
      },
      "source": [
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftJGY_IuV7S5"
      },
      "source": [
        "# Utils functions for GPU usage of neural networks\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSLHkKZpV7S6"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twxj0zfgV7S6"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YlYVv8wV7S6"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjf3ZI9cV7S6"
      },
      "source": [
        "discriminator = to_device(discriminator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-nSz7mV7S7"
      },
      "source": [
        "latent_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8-Ao8TbV7S7"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCI8O3S6V7S7"
      },
      "source": [
        "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
        "fake_images = generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFXxIOpyV7S8"
      },
      "source": [
        "generator = to_device(generator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH8w0n5BV7S8"
      },
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "    # Clear discriminator gradients\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    # Pass real images through discriminator\n",
        "    real_preds = discriminator(real_images)\n",
        "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "\n",
        "    # Pass fake images through discriminator\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "    fake_preds = discriminator(fake_images)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    # Update discriminator weights\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUUTN8oGV7S8"
      },
      "source": [
        "def train_generator(opt_g):\n",
        "    # Clear generator gradients\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # Update generator weights\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pZfVQcOV7S9"
      },
      "source": [
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDPo_XfFV7S9"
      },
      "source": [
        "def save_samples(index, latent_tensors, show=True):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(denorm(fake_images).cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTtzkI4oV7S9"
      },
      "source": [
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_DkWeNV7S9"
      },
      "source": [
        "save_samples(0, fixed_latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqt6M_zAV7S-"
      },
      "source": [
        "def fit(epochs, lr, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "    \n",
        "    # Create optimizers\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            # Train discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            # Train generator\n",
        "            loss_g = train_generator(opt_g)\n",
        "            \n",
        "        # Record losses & scores\n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "        \n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    \n",
        "        # Save generated images\n",
        "        save_samples(epoch+start_idx, fixed_latent, show=True)\n",
        "    \n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON7e9yA4V7S-"
      },
      "source": [
        "lr = 0.0002\n",
        "epochs = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnW4NSHYV7S-"
      },
      "source": [
        "history = fit(epochs, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vhrLBFGV7S-"
      },
      "source": [
        "losses_g, losses_d, real_scores, fake_scores = history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4LPst6V7S_"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc-Ds-vQV7S_"
      },
      "source": [
        "Image('./generated/generated-images-0060.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ghRwIQEV7S_"
      },
      "source": [
        "vid_fname = 'gans_training.mp4'\n",
        "\n",
        "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\n",
        "files.sort()\n",
        "\n",
        "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDFi3Fz7V7S_"
      },
      "source": [
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bXf5oKpV7TA"
      },
      "source": [
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mun7SyNQV7TA"
      },
      "source": [
        "## Улучшаем наш ГАН.\n",
        "\n",
        "\n",
        "1. Попробуйте добавить большеConv-BN блоков в Дискриминатор\n",
        "2. Попробуйте добавить Pooling в Дискриминатор\n",
        "3. Попробуйте добавить больше Conv-BN блоков в Генератор\n",
        "4. Увеличьте `latent_size`\n",
        "5. Попробуйте использовать функцию активации ELU или LeakyReLU\n",
        "\n",
        "Используйте, чтобы получить дополнительные подсказки [source](https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNzMg4gxV7TA"
      },
      "source": [
        "## Генерируем лица!\n",
        "\n",
        "\n",
        "1. Добавьте CenterCrop трансформацию к изображениями и уменьшите их размер\n",
        "2. Используйте более глубокую GAN модель\n",
        "3. Получите модель, которая выдает приемлимый аутпут с достаточно хорошими лицами (Хорошие - субъективный критерий, сделайте визуализацию и обоснуйте \"хорошесть\" модели)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQyX_hzcV7TA"
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PLdTXUV7TA"
      },
      "source": [
        "!tar xvzf tmp.tgz && rm tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR-GzoGpV7TB"
      },
      "source": [
        "DATA_DIR = './lfw-deepfunneled/'\n",
        "image_size = 250\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVgRgYhpV7TB"
      },
      "source": [
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose(#YOUR_CODE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6uS6cykV7TB"
      },
      "source": [
        "#YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtmnlQpaV7TB"
      },
      "source": [
        "# Дополнительное задание на +0.5 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T10:16:29.587457Z",
          "start_time": "2021-04-17T10:16:29.580484Z"
        },
        "id": "p3Mr4BhrV7TB"
      },
      "source": [
        "Overfit it\n",
        "Будем работать с датасетом Fashion-MNIST (hint: он доступен в torchvision) https://github.com/zalandoresearch/fashion-mnist.\n",
        "\n",
        "Ваша задача состоит в следующем:\n",
        "\n",
        "Обучить сеть, которая покажет >= 0.92 test accuracy.\n",
        "Пронаблюдать и продемонстрировать процесс переобучения сети с увеличением числа параметров (==нейронов) и/или числа слоев и продемонстрировать это наглядно (например, на графиках).\n",
        "Попробовать частично справиться с переобучением с помощью подходящих приемов (Dropout/batchnorm/augmentation etc.)\n",
        "Примечание: Пункты 2 и 3 взаимосвязаны, в п.3 Вам прелагается сделать полученную в п.2 сеть менее склонной к переобучению. Пункт 1 является независимым от пунктов 2 и 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7tu0EWWV7TC"
      },
      "source": [
        "#code goes here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}