{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Контрастное обучение с SimCLR\n",
    "[SimCLR](https://arxiv.org/abs/2002.05709) (Simple Contrastive Learning Representation): self-supervised модель, которая используется для получения осмысленных представлений изображений\n",
    "\n",
    "<!-- <img src=\"../images/simclr_im1.png\" alt=\"drawing\" width=\"600\"/> -->\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive learning framework\n",
    "\n",
    "<!-- <img src=\"../images/simclr_im2.png\" alt=\"drawing\" width=\"700\"/> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на CIFAR-10\n",
    "Обучим модель извлечения признаков изображений на наборе данных [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). Для обучения эмбеддингов будем использовать контрастную функцию потерь.\n",
    "\n",
    "Из набора данных выбираем $N$ изображений и для каждого из них получаем 2 избражения, используя 2 случаных преобразования (кроп, изменение цвета) исходного изображения. Пару изображений, полученных от одного изображения будем называть положительной парой, иначе отрицательной. Теперь мы имеем $2N$ изображений\n",
    "\n",
    "Для каждой пары положительной пары $(i,j)$ определим функцию потерь, которая вынуждает модель выдавать близкие по метрике эмбеддинги для положительных пар, и далёкие для отрицательных.\n",
    "\n",
    "$$\n",
    "l_{i,j} = -\\log\\frac{\\exp(\\text{sim}(\\textbf{z}_i, \\textbf{z}_j)/\\tau)}{\\sum_{k=1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\text{sim}(\\textbf{z}_i,\\textbf{z}_k)/\\tau)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{sim}(\\textbf{u}, \\textbf{v}) = \\textbf{u}^T\\textbf{v}/\\left\\lVert\\textbf{u}\\right\\rVert \\left\\lVert\\textbf{v}\\right\\rVert\n",
    "$$\n",
    "\n",
    "Итоговая функция потерь:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{2N}\\sum_{k=1}^N[l(2k-1,2k) + l(2k, 2k - 1)]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели\n",
    "\n",
    "В качестве бекбона будем использовать модификацию [ResNet-50](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "Так как разрешение изображений в наборе данных CIFAR-10, меньше чем в на наборе данных [ImageNet](https://www.image-net.org/), мы заменим первый свёрточный слой с ядром $(7\\times 7)$ и страйдом $2$, на свёрточный слой с ядром размера $(3\\times3)$ и страйдом $1$  \n",
    "Также мы удалим первый maxpolling слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_distortion(s=0.5):\n",
    "    # s is the strength of color distortion.\n",
    "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
    "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
    "    return color_distort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "list(resnet50.children())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_modules = [\n",
    "    nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1)),\n",
    "    nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "] + list(resnet50.children())[4:-1]\n",
    "resnet50_cifar = torch.nn.Sequential(*new_modules).to(device)\n",
    "\n",
    "# summary(resnet50_cifar, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_encoder: torch.nn.Module,\n",
    "        projection_head_hidden_dim=512,\n",
    "        output_dim=128,\n",
    "        temp=1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # define transforms\n",
    "        self.transformations = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(size=(32, 32)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                get_color_distortion(s=0.5),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # define base_encoder x -> h\n",
    "        self.base_encoder = base_encoder\n",
    "\n",
    "        # define projection head h -> z\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(2048, projection_head_hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(projection_head_hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Takes batch of unprocessed images, and computes contrastive loss\n",
    "        \"\"\"\n",
    "\n",
    "        # # compute 2 views of each input image\n",
    "        first_view = self.transformations(X)\n",
    "        second_view = self.transformations(X)\n",
    "\n",
    "        # first_view = []\n",
    "        # second_view = []\n",
    "        # for image in X:\n",
    "        #     first_view.append(torch.unsqueeze(self.transformations(image), dim=0))\n",
    "        #     second_view.append(torch.unsqueeze(self.transformations(image), dim=0))\n",
    "\n",
    "        # compute embeddings\n",
    "\n",
    "        first_view_emb = self.projection_head(\n",
    "            torch.squeeze(self.base_encoder(first_view))\n",
    "        )\n",
    "        first_view_emb = first_view_emb / torch.functional.norm(\n",
    "            first_view_emb, dim=1, keepdim=True\n",
    "        )\n",
    "\n",
    "        second_view_emb = self.projection_head(\n",
    "            torch.squeeze(self.base_encoder(second_view))\n",
    "        )\n",
    "        second_view_emb = second_view_emb / torch.functional.norm(\n",
    "            second_view_emb, dim=1, keepdim=True\n",
    "        )\n",
    "\n",
    "        # compute similarities\n",
    "        view_cat = torch.cat([first_view_emb, second_view_emb], dim=0)  # 2N x d\n",
    "        s = view_cat @ view_cat.T  # 2N x 2N\n",
    "\n",
    "        s = torch.exp(s / self.temp)\n",
    "\n",
    "        # compute loss\n",
    "        s = s.fill_diagonal_(0)\n",
    "\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        positive_pairs = torch.cat(\n",
    "            [torch.diagonal(s, batch_size), torch.diagonal(s, -batch_size)], dim=0\n",
    "        )\n",
    "\n",
    "        loss = torch.mean(-torch.log(positive_pairs / (torch.sum(s, dim=1))))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_PATH, download=True, transform=transform, train=True\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    cifar10_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "cifar10_test = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_PATH, download=True, transform=transform, train=False\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    cifar10_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLR(base_encoder=resnet50_cifar).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(trainloader))[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = resnet50_cifar(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4064, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbd214206844d032e7ca841ed0642b378d73189af10877ee326de88a48fbee75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
