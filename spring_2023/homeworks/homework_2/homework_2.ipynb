{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yikh_fwsKV8z"
      },
      "source": [
        "# **Домашнее задание №2**\n",
        "\n",
        "<!-- В данном задании вам предлагаются 3 задачи: -->\n",
        "\n",
        "Вам предлагается использовать функцию потерь [ArcFace](https://arxiv.org/abs/1801.07698) для решения задачи Metric Learning в распознавании лиц.  \n",
        "Подробное описание задачи вы можете найти в соответствующем разделе домашнего задания.  \n",
        "**Ваша цель:** Обучить две модели для предсказания дискриминативных представлений изображений, $\\textbf{z}\\in\\mathbb{R}^{2}$, с помощью функции потерь SoftMax и функции из статьи [ArcFace](https://arxiv.org/abs/1801.07698) (см. описание задачи 1). Модели необходимо обучить на 8-ми самых многочисленных классах из набора изображений лиц [MS1M-ArcFace](https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_).  Затем нужно изобразить полученные представления на двух рисунках (один для SoftMax другой для ArcFace функций потерь).\n",
        "\n",
        "Рисунок для SoftMax функции будет вам дан.  \n",
        "**Вспомогательный код для загрузки данных и для обучения модели с помощью SoftMax функции потерь вы можете найти в разделе с заданием.**  \n",
        "Помогает ли функция потерь ArcFace для улучшения дикриминативных способностей векторов представлений?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF1gs8LIKV82"
      },
      "source": [
        "## **Задача - обучить небольшой ArcFace модели (1 балл)**\n",
        "\n",
        "При решении задачи распознавания лиц возникает необходимость ответить на вопрос: изображен ли на двух разных картинках один и тот же человек или нет?  \n",
        "На этот вопрос можно ответить с помощью функции расстояния между изображениями, учитывающую абстрактную семантическую информацию.  \n",
        "\n",
        "Современные методы распознавания лиц используют большие наборы данных, содержащие изображения разных людей, для обучения нейросетей, вычисляющих \"осмысленные\" вектора представлений изображений лиц.\n",
        "Для каждого изображения лица человека $\\textbf{x}$ с помощью обучаемой функции $f_{\\theta}(*)$ вычисляется вектор представления $\\textbf{x}$:\n",
        "$$\n",
        "\\textbf{z} = f_{\\theta}(\\textbf{x})\n",
        "$$\n",
        "Параметры $\\theta$ модели подбираются так, чтобы расстояние между векторами представлений изображений разных людей было велико, а между представлениями изображений одного и того же человека - низко:\n",
        "$$\n",
        "d(\\textbf{z}_i,\\textbf{z}_j)>>d(\\textbf{z}_i,\\textbf{z}'_i)\n",
        "$$\n",
        "где $\\mathbf{id}(\\textbf{x}_i)=\\mathbf{id}(\\textbf{x}'_i),\\,\\mathbf{id}(\\textbf{x}_i)\\neq\\mathbf{id}(\\textbf{x}_j)$, $d$ -- некоторая функция расстояния, например, косинусное расстояние:\n",
        "$$\n",
        "d(\\textbf{z}_i,\\textbf{z}_j) = -\\frac{\\langle\\textbf{z}_i,\\textbf{z}_j\\rangle}{\\left\\lVert\\textbf{z}_i\\right\\rVert\\left\\lVert\\textbf{z}_j\\right\\rVert}\n",
        "$$\n",
        "\n",
        "Для получения искомых представлений можно решать задачу классификации на большом наборе данных с изображениями разных людей, а затем использовать вектор перед последним линейным слоем как вектор представления лица.\n",
        "В такой постановке каждый человек в наборе данных рассматривается как отдельный класс, а множество изображений его лица - как представители этого класса.\n",
        "\n",
        "Для решения задачи многоклассовой классификации можно использовать стандартную Softmax функцию потерь:\n",
        "$$\n",
        "    L = -\\frac{1}{N}\\sum_{i=1}^N\\log\\frac{e^{W_{y_i}^T\\textbf{z}_i + b_{y_i}}}{\\sum_{j=1}^ne^{W_{j}^T\\textbf{z}_i + b_{j}}}\n",
        "$$\n",
        "$\\textbf{z}_i$ - представление изображения, $N$ - число изображений в мини батче, $W_j, b_j$ - параметры весов (гиперплоскости) для каждого класса.\n",
        "\n",
        "Если мы отнормируем вектор $\\textbf{x}$ так, чтобы он имел ограниченную норму $s$, положим норму вектора $W_j$ равную 1, а $b_j = 0$, то функция потерь может быть переписана в следующей форме:\n",
        "$$\n",
        "L = -\\frac{1}{N}\\sum_{i=1}^N\n",
        "\\log\n",
        "\\frac{e^{s\\cos\\theta_{y_i}}}\n",
        "{e^{s\\cos\\theta_{y_i}} + \\sum_{j\\neq y_i}^ne^{s\\cos\\theta_{j}}},\n",
        "$$\n",
        "где $\\theta_j$ - угол между представлением $i$-го изображения и вектором $W_j$ указывающим на центр $j$-ой класса.\n",
        "\n",
        "Мы можем видеть, что здесь максимизируется косинус угла между представлением и соответствующим вектором класса.\n",
        "На самом деле мы хотим минимизировать сам угол, а не максимизировать его косинус, потому что угол лучше соответствует близости в пространстве представлений.\n",
        "\n",
        "Для решения этой задачи предлагается [ArcFace](https://arxiv.org/abs/1801.07698) функция потерь:\n",
        "$$\n",
        "L = -\\frac{1}{N}\\sum_{i=1}^N\n",
        "\\log\n",
        "\\frac{e^{s\\cos(\\theta_{y_i}+m)}}\n",
        "{e^{s\\cos(\\theta_{y_i}+m)} + \\sum_{j\\neq y_i}^ne^{s\\cos\\theta_{j}}},\n",
        "$$\n",
        "где вводится параметр отступа $m=0.5$.\n",
        "\n",
        "**Ваша цель:** Исследовать, как функция потерь влияет на качество получаемых представлений изображений лиц.\n",
        "\n",
        "Для этого необходимо:\n",
        "\n",
        "1. Обучить две глубокие модели для получения 2-мерных дискриминативных представлений изображений: первую - с помощью функции потерь SoftMax, а вторую - с помощью функции из статьи [ArcFace](https://arxiv.org/abs/1801.07698) (см. описание задачи 1). Для обучения предлагается использовать изображения 8-ми самых многочисленных классов из набора изображений лиц [MS1M-ArcFace](https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_).\n",
        "    В качестве модели предлагается использовать архитектуру iResNet50, код модели предоставлен в файле ```iresnet.py```. Вспомогательный код для загрузки данных, инициализации и обучения модели с помощью SoftMax функции потерь вы можете найти ниже. Вторую функцию потерь необходимо реализовать самостоятельно. **(0,25 балла)**\n",
        "    \n",
        "2. Оценить качество полученных двумерных представлений изображений визуально, изобразив их на окружности в $\\mathbb{R}^2$. Визуализация представлений, полученных с помощью SoftMax функции приведена в ноутбуке ниже.**(0,25 балла)**\n",
        "    \n",
        "3. В качестве объективной метрики качества посчитать среднее расстояние от представлений изображений одного класса до луча центра класса. Помогает ли функция потерь ArcFace для улучшения дикриминативных способностей векторов представлений? **(0,25 балла)**\n",
        "\n",
        "4. Изучить, как выбор гиперпараметров функции потерь ArcFace (значения нормы $s$ и отступа $m$) влияет на процесс обучения модели и качество полученных представлений. Удается ли получить хорошие представления при $m \\neq 0.5$? **(0,25 балла)**\n",
        "\n",
        "# **Бонусные задания:**\n",
        "\n",
        "1. Решить ту же задачу для 3-мерного пространства представлений $\\textbf{z}_{i}\\in\\mathbb{R}^{3}$, визуализировать полученные представления на шаре. **(0,25 балла)**\n",
        "\n",
        "2. Реализовать [Triplet Loss](https://arxiv.org/abs/1503.03832) и обучить модель с его помощью. Сравнить полученные результаты. **(0,25 балла)**\n",
        "\n",
        "Удачи!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJEANNtzKV83"
      },
      "source": [
        "### Загрузка данных\n",
        "\n",
        "Загрузите выборку MS1M-ArcFace, и распакуйте данные в текущей дериктории:\n",
        "https://drive.google.com/file/d/1SXS4-Am3bsKSK615qbYdbA_FMVh3sAvR/view. Если вы хотите сделать это напрямую в коде, можете воспользоваться командами, закомментированными в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkgT-lIiKV83"
      },
      "outputs": [],
      "source": [
        "#!pip install gdown\n",
        "#!gdown --id 1SXS4-Am3bsKSK615qbYdbA_FMVh3sAvR\n",
        "#!unzip faces_emore.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFg0-YwxKV84"
      },
      "source": [
        "Если вы работаете в Google Colab'е, то вам может потребоваться установить следующие библиотеки, которых там нет по умолчанию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kj7fCJBkKV84",
        "outputId": "95b466a3-c0f7-40a5-f5c6-18749780b319",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# !pip install pytorch_lightning\n",
        "# !pip install mxnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJDqLCGAKV85"
      },
      "source": [
        "### Импортируем необходимые библиотеки\n",
        "\n",
        "Обратите внимание, что мы используем модель iresnet50_normalized, которая определена в файле ```iresnet.py```. Для того чтобы ее импортировать, необходимо положить этот файл в одну папку с данным ноутбуком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T_sYOdweKV85"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mxnet as mx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "import math\n",
        "import numbers\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Optional, Dict\n",
        "\n",
        "from iresnet import iresnet50_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1b3XXgSKV85"
      },
      "source": [
        "### Датасет\n",
        "\n",
        "Ниже определен класс с необходимым нам датасетом изображений лиц. Обратите внимание, что он наследуется от класса ```torch.utils.data.Dataset```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "s2etXusLKV86"
      },
      "outputs": [],
      "source": [
        "class ArcFaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ArcFace dataset loader,\n",
        "    based on https://github.com/deepinsight/insightface/blob/master/recognition/arcface_torch/dataset.py\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir: str, num_labels: int, test: bool = False) -> None:\n",
        "        \"\"\"Initialize ArcFace Dataset.\n",
        "\n",
        "        :param root_dir: path to the folder containing face images\n",
        "        :param num_labels: number of classes (people) to be used\n",
        "        :param test: if True, create test dataset (no augmentations, no labels)\n",
        "        \"\"\"\n",
        "        super(ArcFaceDataset, self).__init__()\n",
        "\n",
        "        self.test = test\n",
        "\n",
        "        # for test dataset, use default transformations (conver to torch.Tensor and normalize),\n",
        "        # do not use augmentations\n",
        "        if self.test:\n",
        "            self.transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToPILImage(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # for train dataset, add augmentations of images (Random horizontal flip)\n",
        "        else:\n",
        "            self.transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToPILImage(),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        path_imgrec = os.path.join(root_dir, \"train.rec\")\n",
        "        path_imgidx = os.path.join(root_dir, \"train.idx\")\n",
        "\n",
        "        # load pictures\n",
        "        self.imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, \"r\")\n",
        "        s = self.imgrec.read_idx(0)\n",
        "        header, _ = mx.recordio.unpack(s)\n",
        "        \n",
        "        self.imgidx = np.array(range(1, int(header.label[0])))\n",
        "\n",
        "        # load or create labels\n",
        "        labels_path = Path(root_dir) / \"labels.npy\"\n",
        "        if labels_path.is_file():\n",
        "            self.labels = np.load(labels_path)\n",
        "        else:\n",
        "            print('Listing labels...')\n",
        "            labels = []\n",
        "            for i in tqdm(range(len(self.imgidx))):\n",
        "                idx = self.imgidx[i]\n",
        "                s = self.imgrec.read_idx(idx)\n",
        "                header, img = mx.recordio.unpack(s)\n",
        "                label = header.label\n",
        "                labels.append(int(label))\n",
        "            self.labels = np.array(labels)\n",
        "            # save labels\n",
        "            np.save(labels_path, self.labels)\n",
        "\n",
        "        unique_labels, unique_counts = np.unique(self.labels, return_counts=True)\n",
        "        top_ids = np.argsort(unique_counts)[::-1][:num_labels]\n",
        "        self.top_labels = unique_labels[top_ids]\n",
        "\n",
        "        self.label_map = dict(\n",
        "            zip(self.top_labels.tolist(), np.arange(len(self.top_labels)))\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, Optional[int]]:\n",
        "        \"\"\"Get item of a dataset.\n",
        "\n",
        "        :param index: index of an item\n",
        "        :return:\n",
        "            - a tuple (image, label) for the train dataset\n",
        "            - image for tht test dataset\n",
        "        \"\"\"\n",
        "        idx = self.imgidx[index]\n",
        "        s = self.imgrec.read_idx(idx)\n",
        "        header, img = mx.recordio.unpack(s)\n",
        "        label = header.label\n",
        "\n",
        "        if not isinstance(label, numbers.Number):\n",
        "            label = label[0]\n",
        "\n",
        "        label = self.label_map[int(label)]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        sample = mx.image.imdecode(img).asnumpy()\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.test:\n",
        "            return sample, label\n",
        "        else:\n",
        "            return sample, label\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return size of the dataset.\"\"\"\n",
        "        return len(self.imgidx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44706it [00:02, 19108.07it/s]\n"
          ]
        }
      ],
      "source": [
        "### создадим подмножество набора данных с небольмим числом часто встречаемых людей\n",
        "# num_people = 100\n",
        "\n",
        "# root_dir = \"data/faces_emore/\"\n",
        "# path_imgrec = os.path.join(root_dir, \"train.rec\")\n",
        "# path_imgidx = os.path.join(root_dir, \"train.idx\")\n",
        "# imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, \"r\")\n",
        "\n",
        "# path_to_data = \"data/faces_emore/\"\n",
        "# path_to_sub_sample_data = \"data/ms1m_subset\"\n",
        "# dataset = ArcFaceDataset(path_to_data, num_labels=num_people, test=True)\n",
        "# people_ids = np.where(np.isin(dataset.labels, dataset.top_labels))[0]\n",
        "\n",
        "# new_record = mx.recordio.MXIndexedRecordIO('data/ms1m_subset/train.idx', 'data/ms1m_subset/train.rec', 'w')\n",
        "# label = np.array([len(people_ids)])\n",
        "# header = mx.recordio.IRHeader(2, label, 0, 0)\n",
        "# packed_s = mx.recordio.pack_img(header, np.zeros([112, 112, 3]))\n",
        "# new_record.write_idx(0, packed_s)\n",
        "# for i, people_id in tqdm(enumerate(people_ids)):\n",
        "#     idx = dataset.imgidx[people_id]\n",
        "#     s = imgrec.read_idx(idx)\n",
        "#     new_record.write_idx(i+1, s)\n",
        "# new_record.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "EbEpqYkHKV86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listing labels...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44705/44705 [00:00<00:00, 45687.73it/s]\n"
          ]
        }
      ],
      "source": [
        "num_people = 4\n",
        "\n",
        "#path_to_data = \"data/faces_emore/\"\n",
        "path_to_data = \"data/ms1m_subset/\"\n",
        "dataset = ArcFaceDataset(path_to_data, num_labels=num_people)\n",
        "people_ids = np.where(np.isin(dataset.labels, dataset.top_labels))[0]\n",
        "people_set = torch.utils.data.Subset(dataset, people_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "F3I_Z39rKV86",
        "outputId": "67439110-fe14-4cd6-91b6-742d0c7b5564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 2342\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset size:\", len(people_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NW6T1HfKV86"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Ниже определен класс для используемое модели. Для удобства обучения мы работаем с библиотекой pytorhc_lightning и испольщуем класс ```pl.LightningModule```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AVJkvsBjKV86"
      },
      "outputs": [],
      "source": [
        "class MetricLearningModel(pl.LightningModule):\n",
        "    \"\"\"Lightning wrapper for a Metric Learning model.\"\"\"\n",
        "    def __init__(\n",
        "        self, backbone: torch.nn.Module, loss: torch.nn.Module, num_labels: int\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize MetricLearningModel.\n",
        "\n",
        "        :param backbone: core deef model to be trained\n",
        "        :param loss: loss function to be used\n",
        "        :param num_labels: number of target classes (people)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.loss = loss\n",
        "\n",
        "        # parameters of the last linear layer initialized by the 'kaiming_uniform_'\n",
        "        self.softmax_weights = torch.nn.Parameter(torch.empty((num_labels, 2)))\n",
        "        torch.nn.init.kaiming_uniform_(self.softmax_weights, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass through the model.\n",
        "\n",
        "        :param x: batch of images\n",
        "        :return a tuple of:\n",
        "            - features: outputs of the backbone model a.k.a. embeddings\n",
        "            - logits: result of the last linear transformations\n",
        "        \"\"\"\n",
        "        backbone_outputs = self.backbone(x)\n",
        "        features = backbone_outputs[\"feature\"]\n",
        "        norm_weights = F.normalize(self.softmax_weights, dim=1)\n",
        "        logits = F.linear(features, norm_weights)\n",
        "        return features, logits\n",
        "\n",
        "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Do a training step of the model.\n",
        "\n",
        "        :param batch: batch of input images\n",
        "        :return: value of the loss function\n",
        "        \"\"\"\n",
        "        images, labels = batch\n",
        "        features, logits = self(images)\n",
        "        loss = self.loss(logits, labels)\n",
        "        # log loss value\n",
        "        self.log(\"train_loss\", loss.item(), prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self) -> Dict[str, torch.optim.Optimizer]:\n",
        "        params = list(self.parameters()) #+ [self.softmax_weights] #list(self.linear_norm.parameters())\n",
        "        optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=5e-5)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1JShlc_KV87"
      },
      "source": [
        "### Инициализация модели\n",
        "\n",
        "В качестве backbone-модели предлагается использовать глубокую сверточную сеть iResNet50. С ее арзитектурой можно ознакомиться в модуле ```iresent.py```.\n",
        "В первом эксперименте мы используем стандартную функцию потерь SoftMax, определенную в ```torch.nn```.\n",
        "Для удобства визуализации мы используем пространство представлений размерности $2$ (```num_features=2```)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rUIeg-zpKV87"
      },
      "outputs": [],
      "source": [
        "backbone_model = iresnet50_normalized(num_features=2)\n",
        "softmax_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "softmax_model = MetricLearningModel(backbone_model, softmax_loss, num_labels=num_people)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8txGw0hOKV87"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "Определяем стандартные гиперпараметры и обучаем модель в течение 20 эпох.\n",
        "Для обучения используем интерфейс ```pytorch_lightning```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wdt6w9lSKV87"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_workers = 2\n",
        "max_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "53667d95101b4c999006253dd6922a07"
          ]
        },
        "id": "fz6WqHvWKV87",
        "outputId": "c9da9295-a96e-47c5-ca02-d12b9ced59d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "\n",
            "  | Name     | Type             | Params\n",
            "----------------------------------------------\n",
            "0 | backbone | IResNetNorm      | 30.8 M\n",
            "1 | loss     | CrossEntropyLoss | 0     \n",
            "----------------------------------------------\n",
            "30.8 M    Trainable params\n",
            "2         Non-trainable params\n",
            "30.8 M    Total params\n",
            "123.178   Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/36 [00:00<?, ?it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/erlygin/miniconda/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 88 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/erlygin/miniconda/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2:  11%|█         | 4/36 [00:03<00:31,  1.03it/s, v_num=34, train_loss=0.813] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/erlygin/miniconda/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "# initialize trainer, use one GPU for training\n",
        "trainer = Trainer(\n",
        "    max_epochs=max_epochs,\n",
        "    default_root_dir=\"outputs/softmax_train\",\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1\n",
        ")\n",
        "\n",
        "# create train dataloader\n",
        "train_dataloader = DataLoader(\n",
        "    people_set,\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "trainer.fit(softmax_model, train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwkVPVzoKV87"
      },
      "source": [
        "### Получение представлений\n",
        "\n",
        "Ниже приведена функция для получения представлений изображений из ```test_dataloader```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ell1avCsKV87"
      },
      "outputs": [],
      "source": [
        "def predict_features(\n",
        "    model: pl.LightningModule, test_dataloader: DataLoader, device: str = \"cuda\"\n",
        ") -> Tuple[np.array, np.array]:\n",
        "    \"\"\"Transform images and get their embeddings.\n",
        "\n",
        "    :param model: trained MetricLearningModel\n",
        "    :param test_dataloader: DataLoader with images to be transformed\n",
        "    :param device: 'gpu' or 'cuda', if available\n",
        "    :return a tuple of:\n",
        "        - numpy array with obtained features\n",
        "        - true image labels (people id's)\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    # switch model to 'eval' mode: disable randomness, dropout, etc.\n",
        "    model.eval()\n",
        "\n",
        "    predicted_features = []\n",
        "    image_labels = []\n",
        "\n",
        "    for images, labels in tqdm(test_dataloader):\n",
        "        images = images.to(device)\n",
        "        features, _ = model(images)\n",
        "        features = features.detach().cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "        predicted_features.append(features)\n",
        "        image_labels.append(labels)\n",
        "\n",
        "    predicted_features = np.concatenate(predicted_features)\n",
        "    image_labels = np.concatenate(image_labels)\n",
        "\n",
        "    return predicted_features, image_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b277OifKKV88",
        "outputId": "f21e120f-bf39-4d57-b28c-539a333af146"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████| 147/147 [00:06<00:00, 21.04it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataloader = DataLoader(\n",
        "    people_set,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "predicted_features, image_labels = predict_features(softmax_model, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysgrdj3LKV88"
      },
      "source": [
        "### Визуализация 2-мерных представлений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNlRP1veKV88"
      },
      "outputs": [],
      "source": [
        "colors = list(mcolors.TABLEAU_COLORS)[:num_people]\n",
        "\n",
        "softmax_weights = softmax_model.softmax_weights.detach().cpu()\n",
        "softmax_weights = F.normalize(softmax_weights, dim=1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvhlwlMdKV88",
        "outputId": "61b3db11-5000-46f9-ef6a-f036c9096a7d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "for i, (weight, color) in enumerate(zip(softmax_weights, colors)):\n",
        "    points = predicted_features[image_labels == i]\n",
        "    x, y = [0, weight[0]], [0, weight[1]]\n",
        "    plt.plot(x, y, marker=\"\", c=color)\n",
        "    plt.scatter(points[:, 0], points[:, 1], color=color, s=3)\n",
        "    if i == (num_people - 1):\n",
        "        break\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162G4RZPKV88"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR2bx-GNKV88"
      },
      "outputs": [],
      "source": [
        "# место для вашего кода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyVW95TsKV88"
      },
      "source": [
        "## Выводы"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
