{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 14. VAE в Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%!pip` not found.\n"
     ]
    }
   ],
   "source": [
    "%!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith(\"1.8.6\")\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "smoke_test = \"CI\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and batching MNIST dataset\n",
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = \"./data\"\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans, download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {\"num_workers\": 10, \"pin_memory\": use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=batch_size, shuffle=True, **kwargs\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc21(hidden))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(784, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the image x\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.reshape(-1, 784)\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder(z)\n",
    "            # score against actual images\n",
    "            pyro.sample(\n",
    "                \"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784)\n",
    "            )\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "optimizer = Adam({\"lr\": 1.0e-3})\n",
    "\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.0\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.0\n",
    "    # compute the loss over the entire test set\n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = True\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 1 if smoke_test else 100\n",
    "TEST_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 000]  average training loss: 190.8656\n",
      "[epoch 000] average test loss: 155.7029\n",
      "[epoch 001]  average training loss: 146.2130\n",
      "[epoch 002]  average training loss: 131.8811\n",
      "[epoch 003]  average training loss: 123.8123\n",
      "[epoch 004]  average training loss: 118.9097\n",
      "[epoch 005]  average training loss: 115.7442\n",
      "[epoch 005] average test loss: 113.5669\n",
      "[epoch 006]  average training loss: 113.5196\n",
      "[epoch 007]  average training loss: 111.8627\n",
      "[epoch 008]  average training loss: 110.5554\n",
      "[epoch 009]  average training loss: 109.5449\n",
      "[epoch 010]  average training loss: 108.7602\n",
      "[epoch 010] average test loss: 107.8704\n",
      "[epoch 011]  average training loss: 108.1038\n",
      "[epoch 012]  average training loss: 107.5468\n",
      "[epoch 013]  average training loss: 107.0950\n",
      "[epoch 014]  average training loss: 106.6665\n",
      "[epoch 015]  average training loss: 106.3654\n",
      "[epoch 015] average test loss: 105.7981\n",
      "[epoch 016]  average training loss: 106.0353\n",
      "[epoch 017]  average training loss: 105.7744\n",
      "[epoch 018]  average training loss: 105.5290\n",
      "[epoch 019]  average training loss: 105.3238\n",
      "[epoch 020]  average training loss: 105.0958\n",
      "[epoch 020] average test loss: 104.6407\n",
      "[epoch 021]  average training loss: 104.9303\n",
      "[epoch 022]  average training loss: 104.7629\n",
      "[epoch 023]  average training loss: 104.5678\n",
      "[epoch 024]  average training loss: 104.4554\n",
      "[epoch 025]  average training loss: 104.3189\n",
      "[epoch 025] average test loss: 103.8395\n",
      "[epoch 026]  average training loss: 104.1829\n",
      "[epoch 027]  average training loss: 104.0958\n",
      "[epoch 028]  average training loss: 103.9422\n",
      "[epoch 029]  average training loss: 103.8636\n",
      "[epoch 030]  average training loss: 103.8049\n",
      "[epoch 030] average test loss: 103.6058\n",
      "[epoch 031]  average training loss: 103.7041\n",
      "[epoch 032]  average training loss: 103.5800\n",
      "[epoch 033]  average training loss: 103.5230\n",
      "[epoch 034]  average training loss: 103.4414\n",
      "[epoch 035]  average training loss: 103.3588\n",
      "[epoch 035] average test loss: 103.1335\n",
      "[epoch 036]  average training loss: 103.2959\n",
      "[epoch 037]  average training loss: 103.1864\n",
      "[epoch 038]  average training loss: 103.1268\n",
      "[epoch 039]  average training loss: 103.1006\n",
      "[epoch 040]  average training loss: 103.0417\n",
      "[epoch 040] average test loss: 102.8720\n",
      "[epoch 041]  average training loss: 102.9669\n",
      "[epoch 042]  average training loss: 102.8973\n",
      "[epoch 043]  average training loss: 102.8636\n",
      "[epoch 044]  average training loss: 102.8046\n",
      "[epoch 045]  average training loss: 102.7462\n",
      "[epoch 045] average test loss: 102.7397\n",
      "[epoch 046]  average training loss: 102.6892\n",
      "[epoch 047]  average training loss: 102.6462\n",
      "[epoch 048]  average training loss: 102.5794\n",
      "[epoch 049]  average training loss: 102.5486\n",
      "[epoch 050]  average training loss: 102.4815\n",
      "[epoch 050] average test loss: 102.5564\n",
      "[epoch 051]  average training loss: 102.4457\n",
      "[epoch 052]  average training loss: 102.4055\n",
      "[epoch 053]  average training loss: 102.3558\n",
      "[epoch 054]  average training loss: 102.3148\n",
      "[epoch 055]  average training loss: 102.2851\n",
      "[epoch 055] average test loss: 102.2916\n",
      "[epoch 056]  average training loss: 102.2239\n",
      "[epoch 057]  average training loss: 102.2059\n",
      "[epoch 058]  average training loss: 102.1580\n",
      "[epoch 059]  average training loss: 102.0763\n",
      "[epoch 060]  average training loss: 102.0720\n",
      "[epoch 060] average test loss: 102.0675\n",
      "[epoch 061]  average training loss: 102.0363\n",
      "[epoch 062]  average training loss: 101.9773\n",
      "[epoch 063]  average training loss: 101.9255\n",
      "[epoch 064]  average training loss: 101.9230\n",
      "[epoch 065]  average training loss: 101.8831\n",
      "[epoch 065] average test loss: 101.9414\n",
      "[epoch 066]  average training loss: 101.8554\n",
      "[epoch 067]  average training loss: 101.7882\n",
      "[epoch 068]  average training loss: 101.7574\n",
      "[epoch 069]  average training loss: 101.7722\n",
      "[epoch 070]  average training loss: 101.7002\n",
      "[epoch 070] average test loss: 101.9390\n",
      "[epoch 071]  average training loss: 101.6592\n",
      "[epoch 072]  average training loss: 101.6145\n",
      "[epoch 073]  average training loss: 101.6248\n",
      "[epoch 074]  average training loss: 101.5693\n",
      "[epoch 075]  average training loss: 101.5321\n",
      "[epoch 075] average test loss: 101.6473\n",
      "[epoch 076]  average training loss: 101.5240\n",
      "[epoch 077]  average training loss: 101.4787\n",
      "[epoch 078]  average training loss: 101.4411\n",
      "[epoch 079]  average training loss: 101.4285\n",
      "[epoch 080]  average training loss: 101.3763\n",
      "[epoch 080] average test loss: 101.5916\n",
      "[epoch 081]  average training loss: 101.3893\n",
      "[epoch 082]  average training loss: 101.3160\n",
      "[epoch 083]  average training loss: 101.3231\n",
      "[epoch 084]  average training loss: 101.2468\n",
      "[epoch 085]  average training loss: 101.2210\n",
      "[epoch 085] average test loss: 101.4731\n",
      "[epoch 086]  average training loss: 101.2460\n",
      "[epoch 087]  average training loss: 101.1494\n",
      "[epoch 088]  average training loss: 101.1410\n",
      "[epoch 089]  average training loss: 101.1019\n",
      "[epoch 090]  average training loss: 101.1006\n",
      "[epoch 090] average test loss: 101.3437\n",
      "[epoch 091]  average training loss: 101.0742\n",
      "[epoch 092]  average training loss: 101.0643\n",
      "[epoch 093]  average training loss: 101.0311\n",
      "[epoch 094]  average training loss: 100.9838\n",
      "[epoch 095]  average training loss: 100.9725\n",
      "[epoch 095] average test loss: 101.3702\n",
      "[epoch 096]  average training loss: 100.9235\n",
      "[epoch 097]  average training loss: 100.9225\n",
      "[epoch 098]  average training loss: 100.8779\n",
      "[epoch 099]  average training loss: 100.8608\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)\n",
    "\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_loaded = VAE()\n",
    "vae_loaded.load_state_dict(torch.load(\"vae.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d27d9e0a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa3UlEQVR4nO3df3BU9b3/8dcmJAtosmkIyWZLwIACrUj8lkKai1IsGUI6l+HX7fVX54Lj4EiDt0CtTjoKop1JxRnr6E3xj6tQZ0SUGYEro8yFYMLYBiwIXy7faobkm0q4kKDcm2wIECL53D+4bruSiCfs5p0Nz8fMmSG755Pz9rjDk8NuDj7nnBMAAP0syXoAAMD1iQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATQ6wH+Kru7m6dPHlSaWlp8vl81uMAADxyzqm9vV2hUEhJSb1f5wy4AJ08eVJ5eXnWYwAArlFTU5NGjRrV6/MDLkBpaWmSpDv0Yw1RivE0AACvvlCXPtC7kd/PexO3AFVWVuq5555Tc3OzCgoK9NJLL2natGlXXfflX7sNUYqG+AgQACSc/73D6NXeRonLhxDefPNNrVq1SmvWrNFHH32kgoIClZSU6PTp0/E4HAAgAcUlQM8//7yWLl2qBx54QN/97nf18ssva/jw4Xr11VfjcTgAQAKKeYAuXryogwcPqri4+K8HSUpScXGxamtrr9i/s7NT4XA4agMADH4xD9Dnn3+uS5cuKScnJ+rxnJwcNTc3X7F/RUWFAoFAZOMTcABwfTD/QdTy8nK1tbVFtqamJuuRAAD9IOafgsvKylJycrJaWlqiHm9paVEwGLxif7/fL7/fH+sxAAADXMyvgFJTUzVlyhRVVVVFHuvu7lZVVZWKiopifTgAQIKKy88BrVq1SosXL9b3v/99TZs2TS+88II6Ojr0wAMPxONwAIAEFJcA3X333frss8+0evVqNTc36/bbb9fOnTuv+GACAOD65XPOOesh/lY4HFYgENBMzeNOCACQgL5wXarWdrW1tSk9Pb3X/cw/BQcAuD4RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJoZYDwAAXnT8Q6HnNc+uW9+nYz3zj//keY07cLRPx7oecQUEADBBgAAAJmIeoKeeeko+ny9qmzhxYqwPAwBIcHF5D+jWW2/V7t27/3qQIbzVBACIFpcyDBkyRMFgMB7fGgAwSMTlPaBjx44pFApp7Nixuv/++3X8+PFe9+3s7FQ4HI7aAACDX8wDVFhYqI0bN2rnzp1av369Ghsbdeedd6q9vb3H/SsqKhQIBCJbXl5erEcCAAxAMQ9QaWmpfvKTn2jy5MkqKSnRu+++q9bWVr311ls97l9eXq62trbI1tTUFOuRAAADUNw/HZCRkaHx48ervr6+x+f9fr/8fn+8xwAADDBx/zmgs2fPqqGhQbm5ufE+FAAggcQ8QI8++qhqamr0l7/8RX/84x+1YMECJScn69577431oQAACSzmfwV34sQJ3XvvvTpz5oxGjhypO+64Q/v27dPIkSNjfSgAQAKLeYA2b94c6285KJyfN837mhHJntdkvlrreQ2QSE5/3/tf3Dzzl7lxmATXinvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm4v4P0uGykzO8t374uFbvB3rV+xLATJL3G+660ec9r5mV/YnnNZJU5fu7Pq3DN8MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN+x+svbvt3he8+zHs+MwCTBwJI8b43nNJz/0fsv32z/8qec1khT603/0aR2+Ga6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3Iy0n6T4vrAeARhwhvzruX45zvmG9H45DrzhCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSPug+47bPa+5c+gHsR8ESHA33XCmX46Tt/tSvxwH3nAFBAAwQYAAACY8B2jv3r2aO3euQqGQfD6ftm3bFvW8c06rV69Wbm6uhg0bpuLiYh07dixW8wIABgnPAero6FBBQYEqKyt7fH7dunV68cUX9fLLL2v//v264YYbVFJSogsXLlzzsACAwcPzhxBKS0tVWlra43POOb3wwgt64oknNG/ePEnSa6+9ppycHG3btk333HPPtU0LABg0YvoeUGNjo5qbm1VcXBx5LBAIqLCwULW1tT2u6ezsVDgcjtoAAINfTAPU3NwsScrJyYl6PCcnJ/LcV1VUVCgQCES2vLy8WI4EABigzD8FV15erra2tsjW1NRkPRIAoB/ENEDBYFCS1NLSEvV4S0tL5Lmv8vv9Sk9Pj9oAAINfTAOUn5+vYDCoqqqqyGPhcFj79+9XUVFRLA8FAEhwnj8Fd/bsWdXX10e+bmxs1OHDh5WZmanRo0drxYoV+vWvf61bbrlF+fn5evLJJxUKhTR//vxYzg0ASHCeA3TgwAHdddddka9XrVolSVq8eLE2btyoxx57TB0dHXrooYfU2tqqO+64Qzt37tTQoUNjNzUAIOF5DtDMmTPlnOv1eZ/Pp6efflpPP/30NQ02kH3698M8r8lOHh6HSYCBY8hNoz2v+YfMf4vDJFca1vjffVrHLUzjy/xTcACA6xMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMeL4bNqQhN7f3y3EufJLRL8cBYqHphRs8r5nu7/a85pXwKM9r1Br2vgZxxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EOYNkHvN+oEYNXctYIz2taFo3v07Ey//GE5zU141/pw5GGel6xvnK+5zXZLX/0vAbxxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EOYOczvf/54IY4zBFL3Xf+H89rXLLP85qmYr/nNZJ0MdTleU1S6iXPa/79zpc8r0nxfhrUfKlv5+HJ/7/A85r/6vZ+89zhSd7PXc7+ds9rnOcV6A9cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZaR90XkjxvKa7D7dD3PCr33pe82/Lb/e8pj89PuJfPa9Jkve7cJ53Fz2vkaSTl7zfHPNfPpvpeU3x7hWe12QcSvW8JvffWzyvkSTfpyc8r/ns42Ge1+Qke7/5q/vTf3heg4GJKyAAgAkCBAAw4TlAe/fu1dy5cxUKheTz+bRt27ao55csWSKfzxe1zZkzJ1bzAgAGCc8B6ujoUEFBgSorK3vdZ86cOTp16lRke+ONN65pSADA4OP5QwilpaUqLS392n38fr+CwWCfhwIADH5xeQ+ourpa2dnZmjBhgpYtW6YzZ870um9nZ6fC4XDUBgAY/GIeoDlz5ui1115TVVWVnn32WdXU1Ki0tFSXevl4a0VFhQKBQGTLy8uL9UgAgAEo5j8HdM8990R+fdttt2ny5MkaN26cqqurNWvWrCv2Ly8v16pVqyJfh8NhIgQA14G4fwx77NixysrKUn19fY/P+/1+paenR20AgMEv7gE6ceKEzpw5o9zc3HgfCgCQQDz/FdzZs2ejrmYaGxt1+PBhZWZmKjMzU2vXrtWiRYsUDAbV0NCgxx57TDfffLNKSkpiOjgAILF5DtCBAwd01113Rb7+8v2bxYsXa/369Tpy5Ih+//vfq7W1VaFQSLNnz9Yzzzwjv98fu6kBAAnP55zzfpfMOAqHwwoEApqpeRri837Tz4GqsaLI85q8qf8Zh0kSz2fvjfK8ZsT/836TS0lK3fmnPq0bbP7z8b/zvOb//vO/eF6z+exIz2tem8CHlAa6L1yXqrVdbW1tX/u+PveCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImY/5Pc6Fl+ea31CAkrV8etR7juDJ/xWb8c54n3F3leM14fxmESWOAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IAZgZs91ZjwBDXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwMsR4AwOCQ7PP+59n/Hp/ieU3wPc9LMEBxBQQAMEGAAAAmPAWooqJCU6dOVVpamrKzszV//nzV1dVF7XPhwgWVlZVpxIgRuvHGG7Vo0SK1tLTEdGgAQOLzFKCamhqVlZVp37592rVrl7q6ujR79mx1dHRE9lm5cqXeeecdbdmyRTU1NTp58qQWLlwY88EBAInN04cQdu7cGfX1xo0blZ2drYMHD2rGjBlqa2vTK6+8ok2bNulHP/qRJGnDhg36zne+o3379ukHP/hB7CYHACS0a3oPqK2tTZKUmZkpSTp48KC6urpUXFwc2WfixIkaPXq0amtre/wenZ2dCofDURsAYPDrc4C6u7u1YsUKTZ8+XZMmTZIkNTc3KzU1VRkZGVH75uTkqLm5ucfvU1FRoUAgENny8vL6OhIAIIH0OUBlZWU6evSoNm/efE0DlJeXq62tLbI1NTVd0/cDACSGPv0g6vLly7Vjxw7t3btXo0aNijweDAZ18eJFtba2Rl0FtbS0KBgM9vi9/H6//H5/X8YAACQwT1dAzjktX75cW7du1Z49e5Sfnx/1/JQpU5SSkqKqqqrIY3V1dTp+/LiKiopiMzEAYFDwdAVUVlamTZs2afv27UpLS4u8rxMIBDRs2DAFAgE9+OCDWrVqlTIzM5Wenq5HHnlERUVFfAIOABDFU4DWr18vSZo5c2bU4xs2bNCSJUskSb/97W+VlJSkRYsWqbOzUyUlJfrd734Xk2EBAIOHpwA55666z9ChQ1VZWanKyso+DwUg8Vxy3d4XcTOw6xr/+wEAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCiT/8iKgDEwrmp56xHgCGugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFEBMJPv48yy84RUDADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqQArtC5e6TnNZdu747DJBjMuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz4nHPOeoi/FQ6HFQgENFPzNMSXYj0OAMCjL1yXqrVdbW1tSk9P73U/roAAACYIEADAhKcAVVRUaOrUqUpLS1N2drbmz5+vurq6qH1mzpwpn88XtT388MMxHRoAkPg8BaimpkZlZWXat2+fdu3apa6uLs2ePVsdHR1R+y1dulSnTp2KbOvWrYvp0ACAxOfpX0TduXNn1NcbN25Udna2Dh48qBkzZkQeHz58uILBYGwmBAAMStf0HlBbW5skKTMzM+rx119/XVlZWZo0aZLKy8t17ty5Xr9HZ2enwuFw1AYAGPw8XQH9re7ubq1YsULTp0/XpEmTIo/fd999GjNmjEKhkI4cOaLHH39cdXV1evvtt3v8PhUVFVq7dm1fxwAAJKg+/xzQsmXL9N577+mDDz7QqFGjet1vz549mjVrlurr6zVu3Lgrnu/s7FRnZ2fk63A4rLy8PH4OCAAS1Df9OaA+XQEtX75cO3bs0N69e782PpJUWFgoSb0GyO/3y+/392UMAEAC8xQg55weeeQRbd26VdXV1crPz7/qmsOHD0uScnNz+zQgAGBw8hSgsrIybdq0Sdu3b1daWpqam5slSYFAQMOGDVNDQ4M2bdqkH//4xxoxYoSOHDmilStXasaMGZo8eXJc/gMAAInJ03tAPp+vx8c3bNigJUuWqKmpST/96U919OhRdXR0KC8vTwsWLNATTzzxtX8P+Le4FxwAJLa4vAd0tVbl5eWppqbGy7cEAFynuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEEOsBvso5J0n6Ql2SMx4GAODZF+qS9Nffz3sz4ALU3t4uSfpA7xpPAgC4Fu3t7QoEAr0+73NXS1Q/6+7u1smTJ5WWliafzxf1XDgcVl5enpqampSenm40oT3Ow2Wch8s4D5dxHi4bCOfBOaf29naFQiElJfX+Ts+AuwJKSkrSqFGjvnaf9PT06/oF9iXOw2Wch8s4D5dxHi6zPg9fd+XzJT6EAAAwQYAAACYSKkB+v19r1qyR3++3HsUU5+EyzsNlnIfLOA+XJdJ5GHAfQgAAXB8S6goIADB4ECAAgAkCBAAwQYAAACYSJkCVlZW66aabNHToUBUWFurDDz+0HqnfPfXUU/L5fFHbxIkTrceKu71792ru3LkKhULy+Xzatm1b1PPOOa1evVq5ubkaNmyYiouLdezYMZth4+hq52HJkiVXvD7mzJljM2ycVFRUaOrUqUpLS1N2drbmz5+vurq6qH0uXLigsrIyjRgxQjfeeKMWLVqklpYWo4nj45uch5kzZ17xenj44YeNJu5ZQgTozTff1KpVq7RmzRp99NFHKigoUElJiU6fPm09Wr+79dZbderUqcj2wQcfWI8Udx0dHSooKFBlZWWPz69bt04vvviiXn75Ze3fv1833HCDSkpKdOHChX6eNL6udh4kac6cOVGvjzfeeKMfJ4y/mpoalZWVad++fdq1a5e6uro0e/ZsdXR0RPZZuXKl3nnnHW3ZskU1NTU6efKkFi5caDh17H2T8yBJS5cujXo9rFu3zmjiXrgEMG3aNFdWVhb5+tKlSy4UCrmKigrDqfrfmjVrXEFBgfUYpiS5rVu3Rr7u7u52wWDQPffcc5HHWltbnd/vd2+88YbBhP3jq+fBOecWL17s5s2bZzKPldOnTztJrqamxjl3+f99SkqK27JlS2Sfjz/+2ElytbW1VmPG3VfPg3PO/fCHP3Q///nP7Yb6Bgb8FdDFixd18OBBFRcXRx5LSkpScXGxamtrDSezcezYMYVCIY0dO1b333+/jh8/bj2SqcbGRjU3N0e9PgKBgAoLC6/L10d1dbWys7M1YcIELVu2TGfOnLEeKa7a2tokSZmZmZKkgwcPqqurK+r1MHHiRI0ePXpQvx6+eh6+9PrrrysrK0uTJk1SeXm5zp07ZzFerwbczUi/6vPPP9elS5eUk5MT9XhOTo4++eQTo6lsFBYWauPGjZowYYJOnTqltWvX6s4779TRo0eVlpZmPZ6J5uZmSerx9fHlc9eLOXPmaOHChcrPz1dDQ4N+9atfqbS0VLW1tUpOTrYeL+a6u7u1YsUKTZ8+XZMmTZJ0+fWQmpqqjIyMqH0H8+uhp/MgSffdd5/GjBmjUCikI0eO6PHHH1ddXZ3efvttw2mjDfgA4a9KS0sjv548ebIKCws1ZswYvfXWW3rwwQcNJ8NAcM8990R+fdttt2ny5MkaN26cqqurNWvWLMPJ4qOsrExHjx69Lt4H/Tq9nYeHHnoo8uvbbrtNubm5mjVrlhoaGjRu3Lj+HrNHA/6v4LKyspScnHzFp1haWloUDAaNphoYMjIyNH78eNXX11uPYubL1wCvjyuNHTtWWVlZg/L1sXz5cu3YsUPvv/9+1D/fEgwGdfHiRbW2tkbtP1hfD72dh54UFhZK0oB6PQz4AKWmpmrKlCmqqqqKPNbd3a2qqioVFRUZTmbv7NmzamhoUG5urvUoZvLz8xUMBqNeH+FwWPv377/uXx8nTpzQmTNnBtXrwzmn5cuXa+vWrdqzZ4/y8/Ojnp8yZYpSUlKiXg91dXU6fvz4oHo9XO089OTw4cOSNLBeD9afgvgmNm/e7Px+v9u4caP785//7B566CGXkZHhmpubrUfrV7/4xS9cdXW1a2xsdH/4wx9ccXGxy8rKcqdPn7YeLa7a29vdoUOH3KFDh5wk9/zzz7tDhw65Tz/91Dnn3G9+8xuXkZHhtm/f7o4cOeLmzZvn8vPz3fnz540nj62vOw/t7e3u0UcfdbW1ta6xsdHt3r3bfe9733O33HKLu3DhgvXoMbNs2TIXCARcdXW1O3XqVGQ7d+5cZJ+HH37YjR492u3Zs8cdOHDAFRUVuaKiIsOpY+9q56G+vt49/fTT7sCBA66xsdFt377djR071s2YMcN48mgJESDnnHvppZfc6NGjXWpqqps2bZrbt2+f9Uj97u6773a5ubkuNTXVffvb33Z33323q6+vtx4r7t5//30n6Ypt8eLFzrnLH8V+8sknXU5OjvP7/W7WrFmurq7Odug4+LrzcO7cOTd79mw3cuRIl5KS4saMGeOWLl066P6Q1tN/vyS3YcOGyD7nz593P/vZz9y3vvUtN3z4cLdgwQJ36tQpu6Hj4Grn4fjx427GjBkuMzPT+f1+d/PNN7tf/vKXrq2tzXbwr+CfYwAAmBjw7wEBAAYnAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDE/wB3z3opkp0DGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = train_loader.dataset[2][0]\n",
    "plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_loaded.to(\"cpu\")\n",
    "vae_loaded.eval()\n",
    "x_rec = vae_loaded.reconstruct_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d05cfdf40>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_rec.reshape(28, 28).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
