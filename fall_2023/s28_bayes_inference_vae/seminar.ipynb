{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 14. VAE в Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%!pip` not found.\n"
     ]
    }
   ],
   "source": [
    "%!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith(\"1.8.6\")\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "smoke_test = \"CI\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and batching MNIST dataset\n",
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = \"./data\"\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans, download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {\"num_workers\": 10, \"pin_memory\": use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=batch_size, shuffle=True, **kwargs\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=batch_size, shuffle=False, **kwargs\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff4b5a7e310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbxklEQVR4nO3df3RU9f3n8dcEyIiaTIwhmUQCJiiiArFFSbMqxZIlxLN+Qdku/uguuC4uNLhFtHriUZHq95sWt+rRpfLHtlDPEX/QFTj6tbgYTFhtwBJhKUfNEjaWuCRBWTITgoSQfPYP1qkDCfQOM3nnx/Nxzj2HzNxP7ru3c3xymcmNzznnBABAH0uyHgAAMDQRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGK49QCn6+7u1sGDB5WSkiKfz2c9DgDAI+ec2tralJOTo6Sk3q9z+l2ADh48qNzcXOsxAADnqbGxUaNHj+71+X4XoJSUFEnSTbpVwzXCeBoAgFcn1akP9W7kv+e9SViAVq1apWeffVbNzc0qKCjQSy+9pKlTp55z3bf/7DZcIzTcR4AAYMD5/3cYPdfbKAn5EMIbb7yhZcuWafny5frkk09UUFCgkpISHTp0KBGHAwAMQAkJ0HPPPaeFCxfq3nvv1TXXXKPVq1frwgsv1O9+97tEHA4AMADFPUAnTpxQbW2tiouL/3aQpCQVFxerpqbmjP07OjoUDoejNgDA4Bf3AH399dfq6upSVlZW1ONZWVlqbm4+Y/+KigoFAoHIxifgAGBoMP9B1PLycoVCocjW2NhoPRIAoA/E/VNwGRkZGjZsmFpaWqIeb2lpUTAYPGN/v98vv98f7zEAAP1c3K+AkpOTNWXKFFVWVkYe6+7uVmVlpYqKiuJ9OADAAJWQnwNatmyZ5s+fr+uvv15Tp07VCy+8oPb2dt17772JOBwAYABKSIDmzZunr776Sk8++aSam5t13XXXafPmzWd8MAEAMHT5nHPOeojvCofDCgQCmq7Z3AkBAAagk65TVdqkUCik1NTUXvcz/xQcAGBoIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPDrQcAzuWLZ4o8r+m6wMV0rFHXfuV5TU3Bf4vpWF6N23qv5zUpH4+M6VhZL/4ppnWAF1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkp+tSRf77S85q91/2XBEwSP52x3ffUs89v+a+e17x6fXZMx3pzyw89r+n6bF9Mx8LQxRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EiZrHcWPSj615PwCTxs7o13/Oa52r+pec1l4/9yvOa/37NW57X3JPS5HmNJP3jggzPa/If5Wak8IYrIACACQIEADAR9wA99dRT8vl8UduECRPifRgAwACXkPeArr32Wr3//vt/O8hw3moCAERLSBmGDx+uYDCYiG8NABgkEvIe0L59+5STk6P8/Hzdc889OnDgQK/7dnR0KBwOR20AgMEv7gEqLCzU2rVrtXnzZr388stqaGjQzTffrLa2th73r6ioUCAQiGy5ubnxHgkA0A/FPUClpaX68Y9/rMmTJ6ukpETvvvuuWltb9eabb/a4f3l5uUKhUGRrbGyM90gAgH4o4Z8OSEtL0/jx41VfX9/j836/X36/P9FjAAD6mYT/HNDRo0e1f/9+ZWdnJ/pQAIABJO4Bevjhh1VdXa0vvvhCf/rTn3T77bdr2LBhuuuuu+J9KADAABb3f4L78ssvddddd+nw4cMaNWqUbrrpJm3fvl2jRo2K96EAAANY3AP0+uv9+2aTONPJGVNiWre1YFUMq0Z4XvHCkfGe13ww73rPayRJBw95XjL+yE7Pa5IuuMDzmn/aMcnzmscy/uJ5jSSdvORkTOsAL7gXHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuG/kA7939HLkmNalxTD319iubFo1T94vwln1/+u87ymL9Wv+J7nNevSfx3DkWL7ZY+jN/N3UyQerzIAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4G7YUNorNTGt+9c7f+J5je9I2POak01feF7T3/2HW9/3vObipNjubA30V1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpYtb16f+yHqFf+OIfizyvuS/tP8dwpAs8r3io6QcxHEdKef8zz2u6YjoShjKugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFPiO1n/r/caiH/077zcWDSR5v7FoTccwz2t2P/M9z2skaWT445jWAV5wBQQAMEGAAAAmPAdo27Ztuu2225STkyOfz6eNGzdGPe+c05NPPqns7GyNHDlSxcXF2rdvX7zmBQAMEp4D1N7eroKCAq1atarH51euXKkXX3xRq1ev1o4dO3TRRReppKREx48fP+9hAQCDh+cPIZSWlqq0tLTH55xzeuGFF/T4449r9uzZkqRXXnlFWVlZ2rhxo+68887zmxYAMGjE9T2ghoYGNTc3q7i4OPJYIBBQYWGhampqelzT0dGhcDgctQEABr+4Bqi5uVmSlJWVFfV4VlZW5LnTVVRUKBAIRLbc3Nx4jgQA6KfMPwVXXl6uUCgU2RobG61HAgD0gbgGKBgMSpJaWlqiHm9paYk8dzq/36/U1NSoDQAw+MU1QHl5eQoGg6qsrIw8Fg6HtWPHDhUVef8JcwDA4OX5U3BHjx5VfX195OuGhgbt3r1b6enpGjNmjJYuXapnnnlGV155pfLy8vTEE08oJydHc+bMiefcAIABznOAdu7cqVtuuSXy9bJlyyRJ8+fP19q1a/XII4+ovb1d999/v1pbW3XTTTdp8+bNuuAC7/e+AgAMXj7nnLMe4rvC4bACgYCma7aG+0ZYj4Mhpv75H3he8/m/6fmHsuNt/Hv/0fuaf78zAZMAZ3fSdapKmxQKhc76vr75p+AAAEMTAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHj+dQzAQHBiy9iY1tVM+HUMq7z/qpGCmvme11z90H7Pa7o8rwD6DldAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKfm94/uWe1zx9xfqYjnVJkvcbi9Z2eD/O2Ke93ya068gR7wcC+jGugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFP3euDf/j+c130vuu79b3VW5yPOa8f/zzwmYBBhYuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1L0qSPzizyvWZH16xiO5I9hjTT/i2LPa65+pN7zmi7PK4DBhysgAIAJAgQAMOE5QNu2bdNtt92mnJwc+Xw+bdy4Mer5BQsWyOfzRW2zZs2K17wAgEHCc4Da29tVUFCgVatW9brPrFmz1NTUFNlee+218xoSADD4eP4QQmlpqUpLS8+6j9/vVzAYjHkoAMDgl5D3gKqqqpSZmamrrrpKixcv1uHDh3vdt6OjQ+FwOGoDAAx+cQ/QrFmz9Morr6iyslK/+tWvVF1drdLSUnV19fzB04qKCgUCgciWm5sb75EAAP1Q3H8O6M4774z8edKkSZo8ebLGjRunqqoqzZgx44z9y8vLtWzZssjX4XCYCAHAEJDwj2Hn5+crIyND9fU9/7Ce3+9Xampq1AYAGPwSHqAvv/xShw8fVnZ2dqIPBQAYQDz/E9zRo0ejrmYaGhq0e/dupaenKz09XStWrNDcuXMVDAa1f/9+PfLII7riiitUUlIS18EBAAOb5wDt3LlTt9xyS+Trb9+/mT9/vl5++WXt2bNHv//979Xa2qqcnBzNnDlTTz/9tPz+2O7NBQAYnDwHaPr06XLO9fr8e++9d14DYeAYflmO5zU3/6cdntdcnNR3f3mp+fQKz2vGH/lzAiYBBj/uBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATcf+V3Bg6PnvM+69O3xh8OwGTnOmWv/w4pnVXP9Lzb+49m66YjgSAKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0XMav/h+RhW+eM+R08CP+2Oad3JI0fiPAmA3nAFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakGJQ6swIxrRtx4rI4T2Kr66uvY1rnOjo8r/H5vd9odtioDM9rYtE1Ki2mdfseSo7vIHHkunwxrZvwQL3nNV3hcEzHOheugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFIPSP//hd9Yj9Av/YtddMa37uiXV85pLRrV5XrNjyjrPa3B+rnl8iec1+Y/UJGASroAAAEYIEADAhKcAVVRU6IYbblBKSooyMzM1Z84c1dXVRe1z/PhxlZWV6dJLL9XFF1+suXPnqqWlJa5DAwAGPk8Bqq6uVllZmbZv364tW7aos7NTM2fOVHt7e2SfBx98UG+//bbWr1+v6upqHTx4UHfccUfcBwcADGyePoSwefPmqK/Xrl2rzMxM1dbWatq0aQqFQvrtb3+rdevW6Uc/+pEkac2aNbr66qu1fft2/eAHP4jf5ACAAe283gMKhUKSpPT0dElSbW2tOjs7VVxcHNlnwoQJGjNmjGpqev4URUdHh8LhcNQGABj8Yg5Qd3e3li5dqhtvvFETJ06UJDU3Nys5OVlpaWlR+2ZlZam5ubnH71NRUaFAIBDZcnNzYx0JADCAxBygsrIy7d27V6+//vp5DVBeXq5QKBTZGhsbz+v7AQAGhph+EHXJkiV65513tG3bNo0ePTryeDAY1IkTJ9Ta2hp1FdTS0qJgMNjj9/L7/fL7/bGMAQAYwDxdATnntGTJEm3YsEFbt25VXl5e1PNTpkzRiBEjVFlZGXmsrq5OBw4cUFFRUXwmBgAMCp6ugMrKyrRu3Tpt2rRJKSkpkfd1AoGARo4cqUAgoPvuu0/Lli1Tenq6UlNT9cADD6ioqIhPwAEAongK0MsvvyxJmj59etTja9as0YIFCyRJzz//vJKSkjR37lx1dHSopKREv/nNb+IyLABg8PA555z1EN8VDocVCAQ0XbM13DfCehycxTfv5Z17p9NUTvxDAibBUHLMnfC8ptN1J2CSnt26Z4HnNaHdGfEfpBfZH570vMb/xz972v+k61SVNikUCik1tfcb23IvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI6TeiApI0sqTB85pr/2mJ5zWun79KUyb8X89rdkxZl4BJ4ufa/3Gv5zXuwEUJmORM+X846n3Rx3+J/yC9uET7+mTNYMAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgop/f5hGDTd5jNdYj9Av/SlOsRzirPO2xHgFDAFdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAlPAaqoqNANN9yglJQUZWZmas6cOaqrq4vaZ/r06fL5fFHbokWL4jo0AGDg8xSg6upqlZWVafv27dqyZYs6Ozs1c+ZMtbe3R+23cOFCNTU1RbaVK1fGdWgAwMA33MvOmzdvjvp67dq1yszMVG1traZNmxZ5/MILL1QwGIzPhACAQem83gMKhUKSpPT09KjHX331VWVkZGjixIkqLy/XsWPHev0eHR0dCofDURsAYPDzdAX0Xd3d3Vq6dKluvPFGTZw4MfL43XffrbFjxyonJ0d79uzRo48+qrq6Or311ls9fp+KigqtWLEi1jEAAAOUzznnYlm4ePFi/fGPf9SHH36o0aNH97rf1q1bNWPGDNXX12vcuHFnPN/R0aGOjo7I1+FwWLm5uZqu2RruGxHLaAAAQyddp6q0SaFQSKmpqb3uF9MV0JIlS/TOO+9o27ZtZ42PJBUWFkpSrwHy+/3y+/2xjAEAGMA8Bcg5pwceeEAbNmxQVVWV8vLyzrlm9+7dkqTs7OyYBgQADE6eAlRWVqZ169Zp06ZNSklJUXNzsyQpEAho5MiR2r9/v9atW6dbb71Vl156qfbs2aMHH3xQ06ZN0+TJkxPyPwAAMDB5eg/I5/P1+PiaNWu0YMECNTY26ic/+Yn27t2r9vZ25ebm6vbbb9fjjz9+1n8H/K5wOKxAIMB7QAAwQCXkPaBztSo3N1fV1dVeviUAYIjiXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPDrQc4nXNOknRSnZIzHgYA4NlJdUr623/Pe9PvAtTW1iZJ+lDvGk8CADgfbW1tCgQCvT7vc+dKVB/r7u7WwYMHlZKSIp/PF/VcOBxWbm6uGhsblZqaajShPc7DKZyHUzgPp3AeTukP58E5p7a2NuXk5Cgpqfd3evrdFVBSUpJGjx591n1SU1OH9AvsW5yHUzgPp3AeTuE8nGJ9Hs525fMtPoQAADBBgAAAJgZUgPx+v5YvXy6/3289iinOwymch1M4D6dwHk4ZSOeh330IAQAwNAyoKyAAwOBBgAAAJggQAMAEAQIAmBgwAVq1apUuv/xyXXDBBSosLNTHH39sPVKfe+qpp+Tz+aK2CRMmWI+VcNu2bdNtt92mnJwc+Xw+bdy4Mep555yefPJJZWdna+TIkSouLta+fftshk2gc52HBQsWnPH6mDVrls2wCVJRUaEbbrhBKSkpyszM1Jw5c1RXVxe1z/Hjx1VWVqZLL71UF198sebOnauWlhajiRPj7zkP06dPP+P1sGjRIqOJezYgAvTGG29o2bJlWr58uT755BMVFBSopKREhw4dsh6tz1177bVqamqKbB9++KH1SAnX3t6ugoICrVq1qsfnV65cqRdffFGrV6/Wjh07dNFFF6mkpETHjx/v40kT61znQZJmzZoV9fp47bXX+nDCxKuurlZZWZm2b9+uLVu2qLOzUzNnzlR7e3tknwcffFBvv/221q9fr+rqah08eFB33HGH4dTx9/ecB0lauHBh1Oth5cqVRhP3wg0AU6dOdWVlZZGvu7q6XE5OjquoqDCcqu8tX77cFRQUWI9hSpLbsGFD5Ovu7m4XDAbds88+G3mstbXV+f1+99prrxlM2DdOPw/OOTd//nw3e/Zsk3msHDp0yEly1dXVzrlT/9+PGDHCrV+/PrLPZ5995iS5mpoaqzET7vTz4JxzP/zhD93PfvYzu6H+Dv3+CujEiROqra1VcXFx5LGkpCQVFxerpqbGcDIb+/btU05OjvLz83XPPffowIED1iOZamhoUHNzc9TrIxAIqLCwcEi+PqqqqpSZmamrrrpKixcv1uHDh61HSqhQKCRJSk9PlyTV1taqs7Mz6vUwYcIEjRkzZlC/Hk4/D9969dVXlZGRoYkTJ6q8vFzHjh2zGK9X/e5mpKf7+uuv1dXVpaysrKjHs7Ky9PnnnxtNZaOwsFBr167VVVddpaamJq1YsUI333yz9u7dq5SUFOvxTDQ3N0tSj6+Pb58bKmbNmqU77rhDeXl52r9/vx577DGVlpaqpqZGw4YNsx4v7rq7u7V06VLdeOONmjhxoqRTr4fk5GSlpaVF7TuYXw89nQdJuvvuuzV27Fjl5ORoz549evTRR1VXV6e33nrLcNpo/T5A+JvS0tLInydPnqzCwkKNHTtWb775pu677z7DydAf3HnnnZE/T5o0SZMnT9a4ceNUVVWlGTNmGE6WGGVlZdq7d++QeB/0bHo7D/fff3/kz5MmTVJ2drZmzJih/fv3a9y4cX09Zo/6/T/BZWRkaNiwYWd8iqWlpUXBYNBoqv4hLS1N48ePV319vfUoZr59DfD6OFN+fr4yMjIG5etjyZIleuedd/TBBx9E/fqWYDCoEydOqLW1NWr/wfp66O089KSwsFCS+tXrod8HKDk5WVOmTFFlZWXkse7ublVWVqqoqMhwMntHjx7V/v37lZ2dbT2Kmby8PAWDwajXRzgc1o4dO4b86+PLL7/U4cOHB9XrwzmnJUuWaMOGDdq6davy8vKinp8yZYpGjBgR9Xqoq6vTgQMHBtXr4VznoSe7d++WpP71erD+FMTf4/XXX3d+v9+tXbvWffrpp+7+++93aWlprrm52Xq0PvXQQw+5qqoq19DQ4D766CNXXFzsMjIy3KFDh6xHS6i2tja3a9cut2vXLifJPffcc27Xrl3ur3/9q3POuV/+8pcuLS3Nbdq0ye3Zs8fNnj3b5eXluW+++cZ48vg623loa2tzDz/8sKupqXENDQ3u/fffd9///vfdlVde6Y4fP249etwsXrzYBQIBV1VV5ZqamiLbsWPHIvssWrTIjRkzxm3dutXt3LnTFRUVuaKiIsOp4+9c56G+vt794he/cDt37nQNDQ1u06ZNLj8/302bNs148mgDIkDOOffSSy+5MWPGuOTkZDd16lS3fft265H63Lx581x2drZLTk52l112mZs3b56rr6+3HivhPvjgAyfpjG3+/PnOuVMfxX7iiSdcVlaW8/v9bsaMGa6urs526AQ423k4duyYmzlzphs1apQbMWKEGzt2rFu4cOGg+0taT//7Jbk1a9ZE9vnmm2/cT3/6U3fJJZe4Cy+80N1+++2uqanJbugEONd5OHDggJs2bZpLT093fr/fXXHFFe7nP/+5C4VCtoOfhl/HAAAw0e/fAwIADE4ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIn/B23zqySm7p5BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(test_loader.dataset[1][0].detach().numpy()[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 28 * 28)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        loc_img = self.sigmoid(self.fc21(hidden))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28 * 28)\n",
    "\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, use_cuda) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # p(x,z) = p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "            loc_img = self.decoder(z)\n",
    "\n",
    "            pyro.sample(\n",
    "                \"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784)\n",
    "            )\n",
    "\n",
    "    def guide(self, x):\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    def reconstruct_img(self, x):\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.0\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.0\n",
    "    # compute the loss over the entire test set\n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = True\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 100\n",
    "TEST_FREQUENCY = 5\n",
    "z_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)\n",
    "\n",
    "# # clear param store\n",
    "# pyro.clear_param_store()\n",
    "\n",
    "# # setup the VAE\n",
    "# vae = VAE(use_cuda=USE_CUDA, z_dim=z_dim, hidden_dim=500)\n",
    "\n",
    "# # setup the optimizer\n",
    "# adam_args = {\"lr\": LEARNING_RATE}\n",
    "# optimizer = Adam(adam_args)\n",
    "\n",
    "# # setup the inference algorithm\n",
    "# svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# train_elbo = []\n",
    "# test_elbo = []\n",
    "# # training loop\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "#     train_elbo.append(-total_epoch_loss_train)\n",
    "#     print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "#     if epoch % TEST_FREQUENCY == 0:\n",
    "#         # report test diagnostics\n",
    "#         total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "#         test_elbo.append(-total_epoch_loss_test)\n",
    "#         print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vae.state_dict(), f\"vae_z_dim-{vae.z_dim}_hid-{500}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VAE:\n\tMissing key(s) in state_dict: \"encoder.fc21.weight\", \"encoder.fc21.bias\", \"encoder.fc22.weight\", \"encoder.fc22.bias\", \"decoder.fc21.weight\", \"decoder.fc21.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.fc2.weight\", \"encoder.fc2.bias\", \"encoder.fc31.weight\", \"encoder.fc31.bias\", \"encoder.fc32.weight\", \"encoder.fc32.bias\", \"decoder.fc2.weight\", \"decoder.fc2.bias\", \"decoder.fc31.weight\", \"decoder.fc31.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/app/fall_2023/s28_bayes_inference_vae/seminar.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f65726c7967696e5f73656d696e617273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31362e38382e3838227d7d/app/fall_2023/s28_bayes_inference_vae/seminar.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vae_loaded \u001b[39m=\u001b[39m VAE(z_dim\u001b[39m=\u001b[39mz_dim, hidden_dim\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, use_cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f65726c7967696e5f73656d696e617273222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31362e38382e3838227d7d/app/fall_2023/s28_bayes_inference_vae/seminar.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m vae_loaded\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvae_z_dim-\u001b[39;49m\u001b[39m{\u001b[39;49;00mz_dim\u001b[39m}\u001b[39;49;00m\u001b[39m_hid-\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39m500\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VAE:\n\tMissing key(s) in state_dict: \"encoder.fc21.weight\", \"encoder.fc21.bias\", \"encoder.fc22.weight\", \"encoder.fc22.bias\", \"decoder.fc21.weight\", \"decoder.fc21.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.fc2.weight\", \"encoder.fc2.bias\", \"encoder.fc31.weight\", \"encoder.fc31.bias\", \"encoder.fc32.weight\", \"encoder.fc32.bias\", \"decoder.fc2.weight\", \"decoder.fc2.bias\", \"decoder.fc31.weight\", \"decoder.fc31.bias\". "
     ]
    }
   ],
   "source": [
    "vae_loaded = VAE(z_dim=z_dim, hidden_dim=500, use_cuda=True)\n",
    "vae_loaded.load_state_dict(torch.load(f\"vae_z_dim-{z_dim}_hid-{500}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
