import torch
import copy
import torch.nn as nn
import numpy as np

from torch.nn import Module
from torchvision.transforms import transforms
from nn_interpretability.interpretation.lrp.lrp_base import LRPBase


class LRPEpsilon(LRPBase):
    """
    Implements the decision-based interpretability method "LRP-epsilon"
    as outlined in the paper "Layer-Wise Relevance Propagation: An Overview"
    by Montavon et al.

    http://iphome.hhi.de/samek/pdf/MonXAI19.pdf
    """

    def __init__(
        self,
        model: Module,
        classes: [str],
        preprocess: transforms.Compose,
        visualize_layer=0,
        input_z_beta=True,
        treat_avgpool=False,
    ):
        """
        :param model: The model the decisions of which needs to be interpreted.
        :param classes: A collection of all classes that the given model can classify.
        :param preprocess: The preprocessing functions that need to be invoked for the model input.
        :param visualize_layer: Select the layer we want to visualize heatmap.
        :param input_z_beta: Switch for using LRP z^beta rule at input layers.
        :param treat_avgpool: Switch for treat max pooling like average pooling described in Montavon's paper.
        """
        super(LRPEpsilon, self).__init__(model, classes, preprocess)
        self.visualize_layer = visualize_layer
        self.input_z_beta = input_z_beta
        self.treat_avgpool = treat_avgpool

    def interpret(self, x):
        # Create a list to collect all layers
        x = x.detach().to(self.device)
        self.A = [x]
        layers = self.to_conv(x)
        L = len(layers)
        for l in range(L):
            self.A.append(layers[l].forward(self.A[l]))

        _, self.predicted_class = torch.max(self.A[-1], dim=1)
        if self.classes == "predicted":
            self.classes = self.predicted_class.item()

        # Relevance score
        num_cls = self.A[-1].size(1)
        T = torch.FloatTensor(
            (1.0 * (np.arange(num_cls) == self.classes).reshape([1, num_cls, 1, 1]))
        )
        self.Relevance = [None] * L + [self.A[-1].detach() * T.to(self.device)]

        # Uncomment this and comment "self.LRP_layers = layers" if you have enough GPU memory.
        # This is to make sure that when we treat max pooling as average pooling we don't change the original layer
        # self.LRP_layers = copy.deepcopy(layers)
        self.LRP_layers = layers

        # LRPã€€backward passincr_p
        for l in range(self.visualize_layer, L)[::-1]:
            self.A[l] = (self.A[l].detach().to(self.device)).requires_grad_(True)
            incr = lambda z: z + 1e-9 + 0.1 * ((z**2).mean() ** 0.5).detach()

            if isinstance(self.LRP_layers[l], torch.nn.MaxPool2d) or isinstance(
                self.LRP_layers[l], torch.nn.AdaptiveAvgPool2d
            ):

                if self.treat_avgpool:
                    # treat max pooling like average pooling described in Montavon's paper
                    self.LRP_layers[l] = torch.nn.AvgPool2d(2)

                z = incr(self.LRP_layers[l].forward(self.A[l]))  # step 1
                s = (self.Relevance[l + 1] / z).detach()  # step 2
                (z * s).sum().backward()
                c = self.A[l].grad  # step 3
                self.Relevance[l] = (self.A[l] * c).detach()  # step 4

            elif isinstance(self.LRP_layers[l], torch.nn.Conv2d):

                z = incr(self.LRP_layers[l].forward(self.A[l]))  # step 1
                s = (self.Relevance[l + 1] / z).detach()  # step 2
                (z * s).sum().backward()
                c = self.A[l].grad  # step 3
                self.Relevance[l] = (self.A[l] * c).detach()  # step 4

            else:
                self.Relevance[l] = self.Relevance[l + 1]

        if (self.input_z_beta == True) and (self.visualize_layer == 0):
            self.lrp_pixel()

        return self.Relevance[self.visualize_layer]
